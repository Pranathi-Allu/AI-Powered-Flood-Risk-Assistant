{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13057453,"sourceType":"datasetVersion","datasetId":8178040}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:10:41.799020Z","iopub.execute_input":"2025-09-14T16:10:41.799303Z","iopub.status.idle":"2025-09-14T16:10:43.137120Z","shell.execute_reply.started":"2025-09-14T16:10:41.799281Z","shell.execute_reply":"2025-09-14T16:10:43.136387Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"The final dataset kerala_flood_final_withRainfall_WITH_LABELS.csv was created by merging raw flood event records (2018) with geographic and environmental data — including average annual rainfall, distance to rivers, population density, and district-level characteristics (coastal, hilly, riverine). This unified dataset serves as the input for training the flood risk prediction model, ensuring predictions are based on physical factors rather than historical labels alone.\n\nFor reference, I added some python files for merging the datasets and creating csv files.\n","metadata":{}},{"cell_type":"markdown","source":"Refer kerala_flood_enhanced.py, kerala_flood_rainfall.py, kerala_flood_with_district.py, kerala_flood_with_population.py, kerala_flood_with_river.py, add_flooded_coulumn.py \nfor the respective merged datasets.","metadata":{}},{"cell_type":"code","source":"# Load final data\ndf = pd.read_csv(r\"/kaggle/input/ai-powered-flood-risk-assistant/data/preprocessed/kerala_flood_final_withRainfall_WITH_LABELS.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:20:33.568361Z","iopub.execute_input":"2025-09-14T16:20:33.568923Z","iopub.status.idle":"2025-09-14T16:20:33.627473Z","shell.execute_reply.started":"2025-09-14T16:20:33.568898Z","shell.execute_reply":"2025-09-14T16:20:33.626709Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   occurrence  label                                               .geo  \\\n0           7      0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...   \n1           0      0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...   \n2           1      0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...   \n3           6      0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...   \n4           9      0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...   \n\n    latitude  longitude        district  distance_to_river_km  \\\n0  10.709939  76.780040        Palakkad              0.327784   \n1  10.227095  76.342112       Ernakulam              0.407700   \n2   9.211999  76.665505  Pathanamthitta              0.202187   \n3   9.366958  76.400502       Alappuzha              0.386800   \n4  10.296714  76.586903        Thrissur              0.322344   \n\n   population_density  avg_annual_rainfall_mm  flooded_2018  \n0           18.120340                 6.58044           1.0  \n1           12.373452                 6.58044           1.0  \n2            0.000000                 6.58044           1.0  \n3            0.000000                 6.58044           1.0  \n4           13.890693                 6.58044           1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>occurrence</th>\n      <th>label</th>\n      <th>.geo</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>district</th>\n      <th>distance_to_river_km</th>\n      <th>population_density</th>\n      <th>avg_annual_rainfall_mm</th>\n      <th>flooded_2018</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>0</td>\n      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n      <td>10.709939</td>\n      <td>76.780040</td>\n      <td>Palakkad</td>\n      <td>0.327784</td>\n      <td>18.120340</td>\n      <td>6.58044</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n      <td>10.227095</td>\n      <td>76.342112</td>\n      <td>Ernakulam</td>\n      <td>0.407700</td>\n      <td>12.373452</td>\n      <td>6.58044</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n      <td>9.211999</td>\n      <td>76.665505</td>\n      <td>Pathanamthitta</td>\n      <td>0.202187</td>\n      <td>0.000000</td>\n      <td>6.58044</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>0</td>\n      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n      <td>9.366958</td>\n      <td>76.400502</td>\n      <td>Alappuzha</td>\n      <td>0.386800</td>\n      <td>0.000000</td>\n      <td>6.58044</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>0</td>\n      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n      <td>10.296714</td>\n      <td>76.586903</td>\n      <td>Thrissur</td>\n      <td>0.322344</td>\n      <td>13.890693</td>\n      <td>6.58044</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define geographic context features based on domain knowledge\ndistrict_info = {\n    \"Thiruvananthapuram\": {\"coastal\": True, \"hilly\": False, \"riverine\": True},\n    \"Kollam\": {\"coastal\": True, \"hilly\": False, \"riverine\": True},\n    \"Pathanamthitta\": {\"coastal\": False, \"hilly\": True, \"riverine\": True},\n    \"Alappuzha\": {\"coastal\": True, \"hilly\": False, \"riverine\": True},\n    \"Kottayam\": {\"coastal\": False, \"hilly\": False, \"riverine\": True},\n    \"Idukki\": {\"coastal\": False, \"hilly\": True, \"riverine\": True},\n    \"Ernakulam\": {\"coastal\": False, \"hilly\": False, \"riverine\": True},\n    \"Thrissur\": {\"coastal\": False, \"hilly\": False, \"riverine\": True},\n    \"Palakkad\": {\"coastal\": False, \"hilly\": True, \"riverine\": True},\n    \"Malappuram\": {\"coastal\": False, \"hilly\": True, \"riverine\": True},\n    \"Kozhikode\": {\"coastal\": True, \"hilly\": False, \"riverine\": True},\n    \"Wayanad\": {\"coastal\": False, \"hilly\": True, \"riverine\": False},\n    \"Kannur\": {\"coastal\": True, \"hilly\": False, \"riverine\": False},\n    \"Kasaragod\": {\"coastal\": True, \"hilly\": False, \"riverine\": False}\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:21:00.862560Z","iopub.execute_input":"2025-09-14T16:21:00.862896Z","iopub.status.idle":"2025-09-14T16:21:00.869423Z","shell.execute_reply.started":"2025-09-14T16:21:00.862873Z","shell.execute_reply":"2025-09-14T16:21:00.868468Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Add geographic features to dataframe\ndf['is_coastal'] = df['district'].map(lambda x: district_info.get(x, {}).get('coastal', False)).astype(int)\ndf['is_hilly'] = df['district'].map(lambda x: district_info.get(x, {}).get('hilly', False)).astype(int)\ndf['is_riverine'] = df['district'].map(lambda x: district_info.get(x, {}).get('riverine', False)).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:21:17.035103Z","iopub.execute_input":"2025-09-14T16:21:17.036068Z","iopub.status.idle":"2025-09-14T16:21:17.046586Z","shell.execute_reply.started":"2025-09-14T16:21:17.036035Z","shell.execute_reply":"2025-09-14T16:21:17.045712Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# FEATURES: ONLY PHYSICAL + GEOGRAPHIC — NO LATITUDE OR LONGITUDE\nfeature_cols = [\n    'distance_to_river_km',\n    'avg_annual_rainfall_mm',\n    'population_density',\n    'is_coastal',\n    'is_hilly',\n    'is_riverine'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:21:30.724902Z","iopub.execute_input":"2025-09-14T16:21:30.725592Z","iopub.status.idle":"2025-09-14T16:21:30.729443Z","shell.execute_reply.started":"2025-09-14T16:21:30.725562Z","shell.execute_reply":"2025-09-14T16:21:30.728561Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Prepare X, y\nX = df[feature_cols].fillna(0)  # Fill any remaining NaN with 0\ny = df['flooded_2018']          # REAL flood events from 2018 — this is our ground truth\n\n# Log transform population density (helps with skew)\nX['population_density_log'] = np.log1p(X['population_density'])\nX = X.drop(['population_density'], axis=1)  # Drop raw version\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:21:44.157166Z","iopub.execute_input":"2025-09-14T16:21:44.157936Z","iopub.status.idle":"2025-09-14T16:21:44.186041Z","shell.execute_reply.started":"2025-09-14T16:21:44.157907Z","shell.execute_reply":"2025-09-14T16:21:44.185250Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Final feature list after transformation — MUST MATCH APP EXACTLY\nfinal_feature_names = [\n    'distance_to_river_km',\n    'avg_annual_rainfall_mm',\n    'population_density_log',\n    'is_coastal',\n    'is_hilly',\n    'is_riverine'\n]\nX.columns = final_feature_names ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:22:02.966169Z","iopub.execute_input":"2025-09-14T16:22:02.966474Z","iopub.status.idle":"2025-09-14T16:22:02.971184Z","shell.execute_reply.started":"2025-09-14T16:22:02.966449Z","shell.execute_reply":"2025-09-14T16:22:02.970320Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:22:21.768835Z","iopub.execute_input":"2025-09-14T16:22:21.769462Z","iopub.status.idle":"2025-09-14T16:22:21.857071Z","shell.execute_reply.started":"2025-09-14T16:22:21.769438Z","shell.execute_reply":"2025-09-14T16:22:21.856244Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# STRATIFIED K-FOLD CROSS-VALIDATION (5-fold) — TO AVOID OVERFITTING\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = cross_val_score(\n    RandomForestClassifier(\n        n_estimators=100,           # Reduced to prevent overfitting\n        max_depth=8,                # Shallower tree\n        min_samples_split=10,       # Require at least 10 samples to split\n        min_samples_leaf=5,         # Minimum 5 samples in leaf\n        random_state=42,\n        class_weight='balanced',\n        oob_score=True              # Use out-of-bag score for internal validation\n    ),\n    X_scaled, y, cv=skf, scoring='accuracy'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:22:50.428576Z","iopub.execute_input":"2025-09-14T16:22:50.429330Z","iopub.status.idle":"2025-09-14T16:22:51.679337Z","shell.execute_reply.started":"2025-09-14T16:22:50.429303Z","shell.execute_reply":"2025-09-14T16:22:51.678511Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"Cross-Validation Results (5-Fold):\")\nprint(f\"Mean CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\nprint(f\"CV Scores per fold: {cv_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:22:54.364925Z","iopub.execute_input":"2025-09-14T16:22:54.365219Z","iopub.status.idle":"2025-09-14T16:22:54.370993Z","shell.execute_reply.started":"2025-09-14T16:22:54.365198Z","shell.execute_reply":"2025-09-14T16:22:54.370164Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results (5-Fold):\nMean CV Accuracy: 0.857 (+/- 0.047)\nCV Scores per fold: [0.845  0.8925 0.8775 0.8425 0.83  ]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Now train final model on full dataset (with best params)\nmodel = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=8,\n    min_samples_split=10,\n    min_samples_leaf=5,\n    random_state=42,\n    class_weight='balanced',\n    oob_score=True\n)\n\nmodel.fit(X_scaled, y)\n\n# Evaluate on training set \ny_pred_train = model.predict(X_scaled)\ntrain_acc = accuracy_score(y, y_pred_train)\nprint(f\"\\nTraining Accuracy: {train_acc:.3f}\")\nprint(f\"Out-of-Bag Score: {model.oob_score_:.3f}\")\n\n# Split for final holdout test (smaller size to simulate real-world testing)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprint(f\"\\nFinal Test Accuracy (on held-out 20%): {accuracy_score(y_test, y_pred):.3f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=[\"High Risk\", \"Low Risk\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:23:21.409241Z","iopub.execute_input":"2025-09-14T16:23:21.409569Z","iopub.status.idle":"2025-09-14T16:23:21.952701Z","shell.execute_reply.started":"2025-09-14T16:23:21.409542Z","shell.execute_reply":"2025-09-14T16:23:21.951842Z"}},"outputs":[{"name":"stdout","text":"\nTraining Accuracy: 0.869\nOut-of-Bag Score: 0.838\n\nFinal Test Accuracy (on held-out 20%): 0.902\n\nClassification Report:\n              precision    recall  f1-score   support\n\n   High Risk       0.78      0.77      0.77        86\n    Low Risk       0.94      0.94      0.94       314\n\n    accuracy                           0.90       400\n   macro avg       0.86      0.85      0.85       400\nweighted avg       0.90      0.90      0.90       400\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Feature importance\nimportances = model.feature_importances_\nprint(\"\\nTop Feature Importances (Ranked):\")\nfor feat, imp in sorted(zip(final_feature_names, importances), key=lambda x: x[1], reverse=True):\n    print(f\"{feat}: {imp:.4f}\")\n\n# Save artifacts — these will be loaded by app.py\njoblib.dump(model, 'flood_model_v2.pkl')\njoblib.dump(scaler, 'scaler_v2.pkl')\njoblib.dump(final_feature_names, 'feature_names.pkl')\n\nprint(\"\\nArtifacts saved: flood_model_v2.pkl, scaler_v2.pkl, feature_names.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T16:23:39.338551Z","iopub.execute_input":"2025-09-14T16:23:39.338850Z","iopub.status.idle":"2025-09-14T16:23:39.388116Z","shell.execute_reply.started":"2025-09-14T16:23:39.338829Z","shell.execute_reply":"2025-09-14T16:23:39.387318Z"}},"outputs":[{"name":"stdout","text":"\nTop Feature Importances (Ranked):\nis_hilly: 0.6237\nis_riverine: 0.1335\ndistance_to_river_km: 0.1219\nis_coastal: 0.0854\npopulation_density_log: 0.0355\navg_annual_rainfall_mm: 0.0000\n\nArtifacts saved: flood_model_v2.pkl, scaler_v2.pkl, feature_names.pkl\n","output_type":"stream"}],"execution_count":13}]}